{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################\n",
    "# Pre-processing the data #\n",
    "###########################\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "files = ['miller_idle', 'sam_wild', 'layton_idle', 'miller_wild', 'val_idle', 'layton_wild', 'sam_idle', 'val_wild']  #filename in the folder "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "def preprocessing(filename):\n",
    "\n",
    "    d = pd.read_csv(filename)   #read the CSV file\n",
    "    # print (d)\n",
    "    d_drop = d.drop(\"Sensor type\", axis=1)   #drop the first column -- sensor type\n",
    "    #print (d_drop)\n",
    "    d_matrix = d_drop.as_matrix()   # Using pandas again to convert the revised table into a matrix\n",
    "    #print (d_matrix)\n",
    "\n",
    "    n_array = np.array(d_matrix) # now we use numpy to convert the pandas matrix into a Numpy array\n",
    "    #print (n_array)\n",
    "\n",
    "    #delete the last row if the revised row number is odd, otherwise cut last too rows\n",
    "    n_array = n_array[:-1] if len(n_array) % 2 == 1 else n_array[:-2] \n",
    "    #print (n_conc)\n",
    "\n",
    "    #Concatenate the EMG and Accerlaration rows for (nearly) the same time moments\n",
    "    n_conc = np.concatenate((n_array[::2], n_array[1::2]), axis = 1)    \n",
    "    #print (n_conc)\n",
    "\n",
    "    n_del = np.delete(n_conc, [1, 2], axis = 1) #delete the second and third columns of each list in the matrix\n",
    "    #print (n_del)\n",
    "\n",
    "    targets = targets = n_del[1:, 2:5] #target for data t is [x,y,z] of t+1\n",
    "    data = n_del[:-1] # no target for last example, so drop it.\n",
    "    \n",
    "    return data, targets\n",
    "\n",
    "def save_array(array, filename):\n",
    "    np.savetxt(filename + 'processed', array, delimiter=',', fmt = '%f')  #save the output into a file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "num_attributes = 6\n",
    "num_targets = 3\n",
    "\n",
    "data = np.empty((0,num_attributes)) #initializing empty array with proper shape\n",
    "targets = np.empty((0,num_targets)) #empty array for targets\n",
    "\n",
    "#collecting all the data into one set\n",
    "for f in files:\n",
    "    processed_data, processed_targets = preprocessing(f)\n",
    "    data = np.append(data, processed_data, axis=0)\n",
    "    targets = np.append(targets, processed_targets, axis=0)\n",
    "    save_array(processed_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.983087920767\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, targets, test_size=0.33)\n",
    "\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {\n",
    "    'alpha':(0.1, 0.3, 1.0, 3.0, 10.0), \n",
    "    'solver': ('auto') # alternatives: 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga'\n",
    "} #hyperparameters to search through with CV\n",
    "\n",
    "\n",
    "#searching through all combinations of parameters to find best (ranked by CV)\n",
    "reg = GridSearchCV(Ridge(), parameters) \n",
    "reg.fit(X_train, y_train)  \n",
    "\n",
    "#scoring against test set to see how good our model is\n",
    "print(reg.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data:\n",
      "[[-0.093   0.5039 -0.89  ]\n",
      " [ 0.0585  0.6757 -0.753 ]\n",
      " [ 0.4257 -0.089   0.8671]\n",
      " [-0.054  -0.519   0.7109]\n",
      " [-0.316   0.2421 -0.949 ]\n",
      " [-0.007  -0.527   0.7578]\n",
      " [ 0.9648  0.2343 -0.105 ]\n",
      " [ 0.2734 -0.429   0.7539]\n",
      " [ 0.7421  0.2812 -0.57  ]\n",
      " [ 0.2695 -0.359   0.8046]]\n",
      "\n",
      "predictions:\n",
      "[[-0.08558059  0.49781231 -0.89078858]\n",
      " [ 0.06608185  0.66181912 -0.7571996 ]\n",
      " [ 0.42787564 -0.09941802  0.86002548]\n",
      " [-0.04920978 -0.51181435  0.70752002]\n",
      " [-0.31100801  0.24554172 -0.94704633]\n",
      " [-0.00622175 -0.52207282  0.75635613]\n",
      " [ 0.9613154   0.23143152 -0.10426771]\n",
      " [ 0.2735992  -0.42483608  0.75111651]\n",
      " [ 0.73470322  0.27756839 -0.55952956]\n",
      " [ 0.27393895 -0.35854889  0.80151536]]\n",
      "\n",
      "targets:\n",
      "[[-0.089   0.5078 -0.875 ]\n",
      " [ 0.0546  0.6992 -0.761 ]\n",
      " [ 0.4453 -0.042   0.8359]\n",
      " [-0.05   -0.593   0.7148]\n",
      " [-0.316   0.246  -0.949 ]\n",
      " [ 0.0039 -0.539   0.75  ]\n",
      " [ 0.9687 -0.007  -0.07  ]\n",
      " [ 0.2343 -0.46    0.7851]\n",
      " [ 0.7343  0.3164 -0.605 ]\n",
      " [ 0.1835 -0.257   0.8515]]\n"
     ]
    }
   ],
   "source": [
    "print('data:')\n",
    "print(X_test[:10, 2:5])\n",
    "print('\\npredictions:')\n",
    "print(reg.predict(X_test)[:10])\n",
    "print('\\ntargets:')\n",
    "print(y_test[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
